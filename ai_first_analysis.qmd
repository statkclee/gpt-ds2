# AI 부조종사와 함께하는 첫 데이터 분석 {#sec-ai-first}

\index{AI 부조종사} \index{ChatGPT Code Interpreter} \index{데이터 분석 입문}

## 학습 목표 {.unnumbered}

이 장을 마치면 다음을 할 수 있습니다:

- R 설치 없이 ChatGPT만으로 데이터 분석 수행
- AI가 생성한 분석 결과를 해석하고 평가
- Python 코드와 R 코드의 차이점 이해
- R을 배워야 하는 이유를 체험적으로 인식

## 왜 R 설치 전에 AI로 시작할까?

전통적인 데이터 과학 학습은 다음과 같습니다:

1. R 설치 (30분)
2. RStudio 설정 (15분)
3. 패키지 설치 (`tidyverse`, `ggplot2` 등) (30분)
4. 문법 학습 (수 주)
5. 첫 분석 (수 개월 후)

하지만 2026년에는 이 순서가 뒤바뀌었습니다:

1. **ChatGPT로 첫 분석 (5분)**
2. AI 생성 코드 이해 (수 주)
3. R 설치 및 직접 실행 (이후)

이 접근의 장점:
- **즉각적인 성취감**: 5분 만에 첫 데이터 분석 완성
- **동기 부여**: 데이터 과학의 전체 그림을 먼저 봄
- **자연스러운 학습**: AI 코드를 읽으며 문법 익히기

## 실습: 서울시 지하철 데이터 분석

### 준비물

- ChatGPT Plus 계정 (GPT-4 접근 권한)
- 서울시 지하철 이용 현황 CSV 파일 [(공공데이터포털 다운로드)](https://www.data.go.kr)

::: {.callout-tip}
## ChatGPT Plus가 없다면?

무료 Claude.ai 또는 Google AI Studio를 사용할 수 있습니다. 이 장의 실습은 모든 최신 LLM에서 작동합니다.
:::

### 단계 1: 데이터 업로드

1. ChatGPT에 접속 (https://chat.openai.com)
2. GPT-4o 모델 선택
3. 클립 아이콘 클릭 → CSV 파일 업로드

### 단계 2: 자연어로 분석 요청

다음 프롬프트를 입력합니다:

```markdown
이 서울시 지하철 데이터를 분석해주세요:

1. 주말과 평일의 이용 패턴 비교
2. 시간대별 이용자 수 추이
3. 가장 혼잡한 역 Top 10

분석 결과를 한글로 설명하고, 시각화도 만들어주세요.
```

### 단계 3: AI 분석 결과 확인

ChatGPT는 다음을 자동으로 수행합니다:

1. **데이터 로딩**
```python
import pandas as pd
import matplotlib.pyplot as plt

# 파일 읽기
df = pd.read_csv('서울시_지하철_이용현황.csv', encoding='cp949')

# 기본 정보 확인
df.head()
df.info()
```

2. **데이터 전처리**
```python
# 날짜 컬럼 변환
df['날짜'] = pd.to_datetime(df['날짜'])

# 요일 추가
df['요일'] = df['날짜'].dt.day_name()
df['주말여부'] = df['요일'].isin(['Saturday', 'Sunday'])
```

3. **주말 vs 평일 비교**
```python
weekend_vs_weekday = df.groupby('주말여부')['이용자수'].mean()

plt.figure(figsize=(8, 6))
weekend_vs_weekday.plot(kind='bar')
plt.title('주말 vs 평일 평균 이용자 수')
plt.ylabel('평균 이용자 수')
plt.show()
```

4. **시간대별 추이**
```python
hourly_usage = df.groupby('시간대')['이용자수'].mean()

plt.figure(figsize=(12, 6))
hourly_usage.plot(kind='line', marker='o')
plt.title('시간대별 평균 이용자 수')
plt.xlabel('시간대')
plt.ylabel('평균 이용자 수')
plt.grid(True)
plt.show()
```

5. **Top 10 혼잡 역**
```python
top_10_stations = df.groupby('역명')['이용자수'].sum().sort_values(ascending=False).head(10)

plt.figure(figsize=(10, 6))
top_10_stations.plot(kind='barh')
plt.title('이용자 수 Top 10 역')
plt.xlabel('총 이용자 수')
plt.gca().invert_yaxis()
plt.show()
```

### 단계 4: 분석 결과 해석

ChatGPT는 다음과 같은 인사이트를 제공합니다:

> **주요 발견사항:**
>
> 1. **주말 vs 평일**: 평일 이용자가 주말보다 약 2.3배 많음
> 2. **시간대 패턴**: 오전 8-9시, 오후 6-7시에 피크
> 3. **혼잡 역**: 강남역, 신림역, 홍대입구역이 Top 3
> 4. **추가 인사이트**: 토요일 오후는 여가 활동으로 이용 증가

## Python 코드를 R로 변환하기

이제 흥미로운 부분입니다. ChatGPT에게 다음을 요청합니다:

```markdown
위 분석을 R 언어로 변환해주세요.
tidyverse와 ggplot2를 사용해서 동일한 결과를 만들어주세요.
```

ChatGPT의 R 버전 코드:

```{r}
#| eval: false
#| code-fold: true
#| code-summary: "AI가 생성한 R 코드"

library(tidyverse)
library(lubridate)

# 데이터 읽기
df <- read_csv('서울시_지하철_이용현황.csv', locale = locale(encoding = 'cp949'))

# 데이터 전처리
df <- df %>%
  mutate(
    날짜 = ymd(날짜),
    요일 = wday(날짜, label = TRUE, abbr = FALSE),
    주말여부 = 요일 %in% c("토요일", "일요일")
  )

# 주말 vs 평일 비교
weekend_vs_weekday <- df %>%
  group_by(주말여부) %>%
  summarize(평균이용자 = mean(이용자수, na.rm = TRUE))

ggplot(weekend_vs_weekday, aes(x = 주말여부, y = 평균이용자)) +
  geom_col(fill = "steelblue") +
  labs(title = "주말 vs 평일 평균 이용자 수",
       x = "주말 여부",
       y = "평균 이용자 수") +
  theme_minimal()

# 시간대별 추이
hourly_usage <- df %>%
  group_by(시간대) %>%
  summarize(평균이용자 = mean(이용자수, na.rm = TRUE))

ggplot(hourly_usage, aes(x = 시간대, y = 평균이용자)) +
  geom_line(color = "darkblue", size = 1) +
  geom_point(color = "darkblue", size = 2) +
  labs(title = "시간대별 평균 이용자 수",
       x = "시간대",
       y = "평균 이용자 수") +
  theme_minimal() +
  theme(panel.grid.major = element_line(color = "gray80"))

# Top 10 혼잡 역
top_10_stations <- df %>%
  group_by(역명) %>%
  summarize(총이용자 = sum(이용자수, na.rm = TRUE)) %>%
  arrange(desc(총이용자)) %>%
  head(10)

ggplot(top_10_stations, aes(x = reorder(역명, 총이용자), y = 총이용자)) +
  geom_col(fill = "coral") +
  coord_flip() +
  labs(title = "이용자 수 Top 10 역",
       x = "역명",
       y = "총 이용자 수") +
  theme_minimal()
```

## Python vs R: 코드 비교

이제 두 코드를 나란히 놓고 비교해봅시다:

### 데이터 읽기

| Python | R |
|--------|---|
| `pd.read_csv('file.csv')` | `read_csv('file.csv')` |
| pandas 라이브러리 필요 | readr 패키지 (tidyverse 포함) |

### 그룹화 및 집계

| Python | R |
|--------|---|
| `df.groupby('컬럼').mean()` | `df %>% group_by(컬럼) %>% summarize(mean())` |
| 메서드 체이닝 | 파이프 연산자 `%>%` |

### 시각화

| Python | R |
|--------|---|
| `plt.figure()` + `plot()` | `ggplot()` + `geom_*()` |
| matplotlib (절차적) | ggplot2 (선언적) |

## 코드 리뷰: 한 줄씩 이해하기

R 코드를 한 줄씩 분석해봅시다:

### 1. 라이브러리 로딩
```r
library(tidyverse)
```
**왜 필요한가?** tidyverse는 데이터 조작과 시각화를 위한 패키지 모음입니다. Python의 `pandas` + `matplotlib`와 유사합니다.

### 2. 데이터 읽기
```r
df <- read_csv('file.csv')
```
**무엇을 하나?** CSV 파일을 tibble (tidyverse의 데이터프레임)로 읽습니다. `<-`는 할당 연산자입니다.

### 3. 파이프 연산
```r
df %>%
  mutate(...) %>%
  group_by(...) %>%
  summarize(...)
```
**어떻게 작동하나?** `%>%`는 "그리고 나서(then)"의 의미입니다. 왼쪽 결과를 오른쪽 함수의 첫 인자로 전달합니다.

Python 체이닝과 비교:
```python
df.rename().groupby().mean()  # Python
```
```r
df %>% rename() %>% group_by() %>% summarize()  # R
```

### 4. ggplot2 시각화
```r
ggplot(data, aes(x = 컬럼1, y = 컬럼2)) +
  geom_col() +
  labs(title = "제목") +
  theme_minimal()
```
**문법은?** "그래프 문법(Grammar of Graphics)"입니다:
- `ggplot()`: 캔버스 준비
- `aes()`: 데이터 변수를 시각적 속성에 매핑
- `geom_*()`: 그래프 유형 (막대, 선, 점 등)
- `labs()`: 레이블 (제목, 축 이름)
- `theme_*()`: 전체 스타일

## 실습: 직접 수정해보기

ChatGPT에게 다음을 요청하여 코드 수정을 경험해봅시다:

1. **색상 변경**
```markdown
Top 10 역 막대 그래프의 색상을 파란색으로 바꿔주세요.
```

AI 수정:
```r
geom_col(fill = "steelblue")  # coral → steelblue
```

2. **상위 5개만 표시**
```markdown
Top 10이 아니라 Top 5만 보여주세요.
```

AI 수정:
```r
head(10)  # 10 → 5로 변경
```

3. **제목 한글 글꼴**
```markdown
제목이 한글이 깨지지 않도록 폰트를 설정해주세요.
```

AI 추가:
```r
theme(text = element_text(family = "AppleGothic"))
```

## 왜 R을 배워야 하는가?

이 실습을 통해 다음을 발견했을 것입니다:

### AI의 강점
✅ 빠른 프로토타이핑 (5분 만에 분석 완성)
✅ 문법 몰라도 결과 도출
✅ Python ↔ R 자동 변환

### AI의 한계
❌ 한글 글꼴 깨짐 (로컬 환경 고려 못함)
❌ 도메인 지식 부족 (지하철 데이터 특성 모름)
❌ 고급 커스터마이징 어려움

### R을 배워야 하는 이유
- AI 생성 코드를 **검증**하고 **수정**할 수 있어야 함
- **도메인 특화 분석**은 인간의 판단 필요
- **프로덕션 배포**에는 R 환경 직접 설정 필수

## 다음 단계

이제 여러분은:
1. ✅ AI로 데이터 분석의 전체 그림을 경험했습니다
2. ✅ Python과 R 코드의 차이를 알게 되었습니다
3. ✅ R을 배워야 하는 동기를 얻었습니다

**다음 장 (3장 "펭귄 데이터로 배우는 AI-인간 협업")**에서는:
- R을 실제로 설치하고
- AI가 생성한 코드를 직접 실행하며
- 조금씩 코드를 수정하는 방법을 배웁니다

## 연습 문제

1. **AI 활용**: ChatGPT에게 "이 분석을 Python이 아니라 R로 처음부터 다시 작성해줘"라고 요청하고 결과를 비교하세요.

2. **코드 읽기**: R 코드에서 `mutate()`, `group_by()`, `summarize()`가 각각 무엇을 하는지 ChatGPT에게 한 줄씩 설명을 요청하세요.

3. **응용**: 자신의 관심 분야 데이터 (예: 주식 가격, 날씨, 스포츠 기록)를 찾아 ChatGPT로 분석해보세요.

::: {.callout-note}
## 이 장의 핵심 교훈

> "AI 시대에 R을 배우는 가장 빠른 방법은 AI가 생성한 R 코드를 읽는 것이다."

AI는 여러분의 **학습 파트너**입니다. AI와 함께 시작하되, 점진적으로 독립성을 키워나가세요.
:::
